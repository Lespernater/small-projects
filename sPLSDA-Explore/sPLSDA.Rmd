---
title: "sPLSDA and multiblock sPLSDA (DIABLO) using mixOmics"
output:
  pdf_document: default
  html_document: default
date: "2022-10-28"
---
```{r include=FALSE}
   options(rgl.useNULL = TRUE)
   rgl::setupKnitr(autoprint = TRUE)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

First we will import mixOmics package and some others for this markdown to work

```{r loading_data, echo = TRUE, message=FALSE}
rm(list = ls()) # Make sure starting with a clean environment
library(knitr)
library(mixOmics)
library(devtools)
library(factoextra)
```

## Load Data

We'll use a subset of data from The Cancer Genome Atlas (TCGA). It is one of the largest collections of multi-omics data sets for more than 33 different types of cancer for 20 000 individual tumor samples. 

As independent variable (X), we'll load in the dataset of miRNA expression levels for 150 samples and their corresponding tumour subtypes (Her2, Basal, or LumA) as categorical outcomes (Y). We'll use this subset to train our model and another to test later to test it. 

```{r loading_data1, echo = TRUE}
data("breast.TCGA") 

X <- breast.TCGA$data.train$mirna # use miRNA expression data of 184 miRNA as X matrix
Y <- breast.TCGA$data.train$subtype # use tumour subtype as the Y matrix

head(X[,1:5]) # Columns are features (miRNAs) and rows are samples (individuals)
```
## PCA first

Let's use our PCA on our X dataset, mixOmics also has a `pca()` function that will do this for us.

```{r PCA and Scree, echo=TRUE}
pca.miRNA <- prcomp(X, center = TRUE, scale = TRUE)

PCs = pca.miRNA$x # Gives us 150 PCs

fviz_eig(pca.miRNA, geom = "bar", main="X Variance Explained by PCA Components", xlab = "Component", ylab = "Variance explained (%)") 
```
*Figure 1: Scree plot of variance explained by each first 10 components.*


```{r Plotting PCAs for clustering tumour types, echo=TRUE}
ggplot(as.data.frame(PCs), aes(y=PC2, x=PC1, colour=Y)) + geom_point(shape=19, size=1) + stat_ellipse() + theme_bw()
```
*Figure 2: Clustering of tumour types in PC1 and PC2.*


Clustering or classification looks pretty tough with these PCs

The `prcomp object` also gives us the loading vectors if we want them  - they're in this rotation matrix. 

```{r Loadings_1}
PCAloadings = pca.miRNA$rotation
head(PCAloadings[1:5,1:5]) # Columns are the loading vectors
```

## Building sPLSDA model + Evaluation

Next let's use sPLSDA to get components that explain more than X. They explain X, explain Y and explain the relationship between X and Y. In addition we will use the sparse version of PLSDA to select for the most crucial features (miRNAs that matter most to determining tumour subtype). 

Let's feed both X and Y into splsda and at first we should specify how many components we would like to come up with, here 8 is used (just arbitrary)


```{r first_model, echo = TRUE}
splsda.breast <- splsda(X = X, Y = Y, ncomp = 8) 
```


Since we didn't specify a `keepX` argument above - this is actually the same as plsda for now.

`perf()` evaluates classification performance for (s)pls(da) objects and creates a `perf object`

```{r Performance_eval}
perf.splsda.breast <- perf(splsda.breast, folds = 10, nrepeat = 50, 
                           dist = "mahalanobis.dist") 

plot(perf.splsda.breast, criterion = 'Q2.total') # Plot the perf object
```

`Q2 total` is a measure of error in our classification model. BER is balanced error rate, most appropriate when there are class imbalances (as we have here)

But we haven't really TUNED our model - our choice of using ncomp = 8 was arbitrary and not informed by the data or the regression. We also haven't really used the 'sparse' part of this method yet because we haven't added any feature selection - right now we are using them all like PCA.

## Tuning Our Model

Let's tune some of these hyperparameters (primarily ncomp, keepX). We'll optimize over a range of keepX values (5-120 in intervals of 5). 

```{r tuning, echo=TRUE}
list.keepX <- c(seq(5, 120, 5))

# Optimize over possible keepX values
tune.splsda.breast <- tune.splsda(X, Y, ncomp = 8,
                             test.keepX = list.keepX,
                             nrepeat = 10, folds = 10)

plot(tune.splsda.breast) # mixOmics makes visualization easy
```
Figure 3: Tuning of model by examining balanced classification error as more components are added to the model. 

The tuning involves 8 models that vary in their number of components (ncomp) where fewer is better, and examining how error rate changes as number of features (keepX) varies. Regardless of how many features are included in the model, a model based on 1 component (ncomp=1) has consistently higher error rate, the model based on the first 3 components (ncomp=3) has consistently lower error but all model based on 4 or more components (ncomp>=4) consistently have the lowest error rate. A model based on the first 2 components is the only that appears to improve significantly as more features are included in the model. 


## Newly Tuned Model + Evaluation

Now let's build the new model based on the hyperparameters we just tuned. 

We have to extract the optimal `keepX` and the optimal `ncomp`. This now counts as *sparse* PLS-DA because we have feature selection.

```{r updating_hyperparameters, echo=TRUE}
optimal.keepX <- tune.splsda.breast$choice.keepX 
optimal.ncomp <-  length(optimal.keepX) # extract optimal number of components

final.splsda.breast <- splsda(X, Y, ncomp = optimal.ncomp, 
                         keepX = optimal.keepX) 

perf.final.splsda.breast <- perf(final.splsda.breast, dist = "mahalanobis.dist", 
                                 folds = 10, nrepeat = 50) 
```

## Let's Visualize the process!

Now let's use the visualizations simplified by mixOmics to see the process and results. What loading vectors go into making the first 3 components?

```{r visualizations, echo = TRUE}
plotLoadings(final.splsda.breast, comp = 1, title = "Loadings for Component 1")
plotLoadings(final.splsda.breast, comp = 2, title = "Loadings for Component 2")
plotLoadings(final.splsda.breast, comp = 3, title = "Loadings for Component 3")
```

### Let's visualize how stable the model is. 

How often it is selecting the same features as most informative through folds/repeats.

```{r Stability_testing}
plot(perf.final.splsda.breast$features$stable$comp1, type = 'h',
     ylab = 'Stability',
     xlab = 'Features',
     main = 'Stability of Comp 1', las =2,
     xlim = c(0, 184),
     ylim = c(0, 1))

plot(perf.final.splsda.breast$features$stable$comp2, type = 'h',
     ylab = 'Stability',
     xlab = 'Features',
     main = 'Stability of Comp 2', las =2,
     xlim = c(0, 184), 
     ylim = c(0, 1))
```


# Let's visualize the results! 

Compare the plot of sPLS-DAs component 1&2 vs PCAs component 1&2 (here using mixOmics `plotIndiv()` function)

``` {r results_visualization, echo =TRUE} 
pca.miRNA = pca(X, center = TRUE, scale = TRUE)

plotIndiv(final.splsda.breast, ind.names = FALSE, 
          rep.space = "X-variate",
          group = breast.TCGA$data.train$subtype, # colour by group
          col.per.group = color.mixo(1:3), 
          legend = TRUE, legend.title = 'Subtype', title = 'sPLSDA comp 1 - 2')

# Let's compare plots
plotIndiv(pca.miRNA, comp = c(1, 2), ind.names = FALSE,
          group = breast.TCGA$data.train$subtype, 
          legend = TRUE, legend.title = 'Subtype', title = 'PCA comp 1 - 2')
```

Much better clustering with sPLS-DA than PCA. 

Some more complex visualizations can also be made relatively easily, excluded here for brevity.


```{r More_complex_viz}
# Some more complex visualizations
# col.tox <- color.mixo(as.numeric(as.factor(c(1,3)))) # create set of colours
# library(rgl) # we'll use this to make a 3D plot 
# plotIndiv(final.splsda.breast, ind.names = FALSE, rep.space = "XY-variate", axes.box = "both", style = '3d')

# Some plots that only really appropriate when using multiblock.splsda
```

## Predictive Modelling

Now let's use the model to predict tumour category when we only have the X input matrix (miRNA expression levels). This test set has 70 samples.

```{r predicting, echo=TRUE}
predict.model = predict(final.splsda.breast, breast.TCGA$data.test$mirna)

confusion.mat <- get.confusion_matrix(
                truth = breast.TCGA$data.test$subtype, 
                predicted = predict.model$MajorityVote$mahalanobis.dist[,5])
kable(confusion.mat)
```

## Same Methods but Multi-block with DIABLO

If we want to perform sPLSDA on N-integrated datasets (omics data) we can use  `multiblock.splsda`, the mixOmics framework is called DIABLO. The procedure is very similar but we add parallel datasets of another modality, like mRNA or protein expression levels, to our X input. 

## Example DIABLO

Let's add mRNA expression levels and proteomics to the input data. We will import omics datasets on breast cancers as independent variables and their tumour subtypes (Her2, Basal, or LumA) as categorical outcomes just as before. Note: each dataset contains measures from the same individuals. 

```{r loading_data2, echo = TRUE}
X1 <- breast.TCGA$data.train$mirna
X2 <- breast.TCGA$data.train$mrna  
X3 <- breast.TCGA$data.train$protein
X_all <- list(mirna = X1, mrna = X2, protein = X3)
Y_all <- breast.TCGA$data.train$subtype # use tumour subtype as the outcome variable
```


```{r model2, echo=TRUE}
list.keepX = list(mirna = c(16, 17), mrna = c(18,5), protein = c(5,5)) 
result.sparse.diablo.breast <-  block.splsda(X_all, Y_all, keepX = list.keepX, ncomp = 5) 
```

Plot the contributions of each feature to each component 1

```{r plotLoadings2, echo=TRUE}
plotLoadings(result.sparse.diablo.breast, ncomp = 1)
```


```{r plotIndiv2, echo=TRUE}
plotIndiv(result.sparse.diablo.breast, var.names = FALSE) # plot the samples
```


```{r more_plotting,echo=TRUE}
plotVar(result.sparse.diablo.breast, cex = c(2,2,2), var.names = FALSE) # plot the variables

circosPlot(result.sparse.diablo.breast, cutoff = 0.7)

```

## Multiomics Integrative Predictive Modelling

```{r predictions2, echo=TRUE}
predict.model.diablo = predict(result.sparse.diablo.breast, list(mirna = breast.TCGA$data.test$mirna, mrna =  breast.TCGA$data.test$mrna), protein = NULL) 
# Note protein data is missing for prediction and that is OK. 

# This is explained in warning below

plotDiablo(result.sparse.diablo.breast)

confusion.mat_diablo <- get.confusion_matrix(
                truth = breast.TCGA$data.test$subtype, 
                predicted = predict.model.diablo$WeightedVote$mahalanobis.dist[,5])
kable(confusion.mat_diablo)
```

And we didn't even properly tune this model! Imagine the possibilities...

# End
